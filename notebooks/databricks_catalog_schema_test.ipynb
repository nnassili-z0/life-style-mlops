{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56e4dfc2",
   "metadata": {},
   "source": [
    "# Databricks Connect catalog bootstrap\n",
    "Use this notebook to validate a Databricks Connect setup and bootstrap Unity Catalog objects so the Kaggle-powered pipeline can land data in Delta tables. It follows the Spark Connect architecture described in the [Databricks blog on Spark Connect](https://www.databricks.com/blog/2023/04/18/spark-connect-available-apache-spark.html), which requires a clean gRPC TLS path from this client to your workspace compute.\n",
    "\n",
    "**What you can do here**\n",
    "1. Validate local environment variables, SSL certificates, and proxy behaviour.\n",
    "2. Merge corporate root certificates into the trust store used by Spark Connect (required when proxies intercept TLS).\n",
    "3. Probe the workspace REST API to confirm the token and host are correct.\n",
    "4. Establish a Databricks Connect session and run smoke-test SQL against remote compute.\n",
    "5. Create (or reuse) the target Unity Catalog catalog and schema for the pipeline.\n",
    "6. Optionally load the latest CSV output into Delta tables and log the run to MLflow.\n",
    "\n",
    "If any step fails, the notebook reports guidance without cascading errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaec0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting mlflow\n",
      "  Obtaining dependency information for mlflow from https://files.pythonhosted.org/packages/52/fe/1ed27f800cd1709a272c6e26b78ec3d77a5ba482171ea1b5bfbcf4c067c0/mlflow-3.4.0-py3-none-any.whl.metadata\n",
      "  Downloading mlflow-3.4.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: databricks-connect in c:\\users\\nnassili\\appdata\\roaming\\python\\python311\\site-packages (15.1.3)\n",
      "Collecting mlflow-skinny==3.4.0 (from mlflow)\n",
      "  Obtaining dependency information for mlflow-skinny==3.4.0 from https://files.pythonhosted.org/packages/1b/94/7acd7c6970cc75da1fd3b550e43d8b99068032022f47b0ef224a137ec679/mlflow_skinny-3.4.0-py3-none-any.whl.metadata\n",
      "  Downloading mlflow_skinny-3.4.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting mlflow-tracing==3.4.0 (from mlflow)\n",
      "  Obtaining dependency information for mlflow-tracing==3.4.0 from https://files.pythonhosted.org/packages/ae/96/403b1191ccf587f19a8c94085477600d6e6b3d61a7aff46f353b20b450f9/mlflow_tracing-3.4.0-py3-none-any.whl.metadata\n",
      "  Downloading mlflow_tracing-3.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: Flask<4 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (2.2.2)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Obtaining dependency information for alembic!=1.10.0,<2 from https://files.pythonhosted.org/packages/44/1f/38e29b06bfed7818ebba1f84904afdc8153ef7b6c7e0d8f3bc6643f5989c/alembic-1.17.0-py3-none-any.whl.metadata\n",
      "  Downloading alembic-1.17.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting cryptography<46,>=43.0.0 (from mlflow)\n",
      "  Obtaining dependency information for cryptography<46,>=43.0.0 from https://files.pythonhosted.org/packages/b3/61/0ab90f421c6194705a99d0fa9f6ee2045d916e4455fdbb095a9c2c9a520f/cryptography-45.0.7-cp311-abi3-win_amd64.whl.metadata\n",
      "  Using cached cryptography-45.0.7-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Obtaining dependency information for docker<8,>=4.0.0 from https://files.pythonhosted.org/packages/e3/26/57c6fb270950d476074c087527a558ccb6f4436657314bfb6cdf484114c4/docker-7.1.0-py3-none-any.whl.metadata\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fastmcp<3,>=2.0.0 (from mlflow)\n",
      "  Obtaining dependency information for fastmcp<3,>=2.0.0 from https://files.pythonhosted.org/packages/e2/c7/562ff39f25de27caec01e4c1e88cbb5fcae5160802ba3d90be33165df24f/fastmcp-2.12.4-py3-none-any.whl.metadata\n",
      "  Downloading fastmcp-2.12.4-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Obtaining dependency information for graphene<4 from https://files.pythonhosted.org/packages/66/e0/61d8e98007182e6b2aca7cf65904721fb2e4bce0192272ab9cb6f69d8812/graphene-3.4.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (3.7.2)\n",
      "Requirement already satisfied: numpy<3 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (1.24.3)\n",
      "Requirement already satisfied: pandas<3 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (2.0.3)\n",
      "Requirement already satisfied: pyarrow<22,>=4.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (11.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (1.3.0)\n",
      "Requirement already satisfied: scipy<2 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (1.11.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow) (1.4.39)\n",
      "Collecting waitress<4 (from mlflow)\n",
      "  Obtaining dependency information for waitress<4 from https://files.pythonhosted.org/packages/8d/57/a27182528c90ef38d82b636a11f606b0cbb0e17588ed205435f8affe3368/waitress-3.0.2-py3-none-any.whl.metadata\n",
      "  Downloading waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in c:\\users\\nnassili\\appdata\\roaming\\python\\python311\\site-packages (from mlflow-skinny==3.4.0->mlflow) (6.2.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.4.0->mlflow) (8.0.4)\n",
      "Requirement already satisfied: cloudpickle<4 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.4.0->mlflow) (2.2.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in c:\\users\\nnassili\\appdata\\roaming\\python\\python311\\site-packages (from mlflow-skinny==3.4.0->mlflow) (0.67.0)\n",
      "Collecting fastapi<1 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Obtaining dependency information for fastapi<1 from https://files.pythonhosted.org/packages/ce/70/584c4d7cad80f5e833715c0a29962d7c93b4d18eed522a02981a6d1b6ee5/fastapi-0.119.0-py3-none-any.whl.metadata\n",
      "  Downloading fastapi-0.119.0-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Obtaining dependency information for gitpython<4,>=3.1.9 from https://files.pythonhosted.org/packages/01/61/d4b89fec821f72385526e1b9d9a3a0385dda4a72b206d28049e2c7cd39b8/gitpython-3.1.45-py3-none-any.whl.metadata\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.4.0->mlflow) (6.0.0)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Obtaining dependency information for opentelemetry-api<3,>=1.9.0 from https://files.pythonhosted.org/packages/91/48/28ed9e55dcf2f453128df738210a980e09f4e468a456fa3c763dbc8be70a/opentelemetry_api-1.37.0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Obtaining dependency information for opentelemetry-proto<3,>=1.9.0 from https://files.pythonhosted.org/packages/c4/25/f89ea66c59bd7687e218361826c969443c4fa15dfe89733f3bf1e2a9e971/opentelemetry_proto-1.37.0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Obtaining dependency information for opentelemetry-sdk<3,>=1.9.0 from https://files.pythonhosted.org/packages/9f/62/9f4ad6a54126fb00f7ed4bb5034964c6e4f00fcd5a905e115bd22707e20d/opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: packaging<26 in c:\\users\\nnassili\\appdata\\roaming\\python\\python311\\site-packages (from mlflow-skinny==3.4.0->mlflow) (25.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in c:\\users\\nnassili\\appdata\\roaming\\python\\python311\\site-packages (from mlflow-skinny==3.4.0->mlflow) (6.32.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.4.0->mlflow) (1.10.8)\n",
      "Requirement already satisfied: python-dotenv<2,>=0.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.4.0->mlflow) (0.21.0)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.4.0->mlflow) (6.0)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.4.0->mlflow) (2.31.0)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Obtaining dependency information for sqlparse<1,>=0.4.0 from https://files.pythonhosted.org/packages/a9/5c/bfd6bd0bf979426d405cc6e71eceb8701b148b16c21d2dc3c261efc61c7b/sqlparse-0.5.3-py3-none-any.whl.metadata\n",
      "  Using cached sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in c:\\users\\nnassili\\appdata\\roaming\\python\\python311\\site-packages (from mlflow-skinny==3.4.0->mlflow) (4.15.0)\n",
      "Collecting uvicorn<1 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Obtaining dependency information for uvicorn<1 from https://files.pythonhosted.org/packages/85/cd/584a2ceb5532af99dd09e50919e3615ba99aa127e9850eafe5f31ddfdb9a/uvicorn-0.37.0-py3-none-any.whl.metadata\n",
      "  Downloading uvicorn-0.37.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.56.4 in c:\\users\\nnassili\\appdata\\roaming\\python\\python311\\site-packages (from databricks-connect) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status>=1.56.0 in c:\\users\\nnassili\\appdata\\roaming\\python\\python311\\site-packages (from databricks-connect) (1.75.1)\n",
      "Requirement already satisfied: grpcio>=1.56.0 in c:\\users\\nnassili\\appdata\\roaming\\python\\python311\\site-packages (from databricks-connect) (1.75.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\nnassili\\appdata\\roaming\\python\\python311\\site-packages (from databricks-connect) (0.10.9.7)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from databricks-connect) (1.16.0)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Obtaining dependency information for Mako from https://files.pythonhosted.org/packages/87/fb/99f81ac72ae23375f22b7afdb7642aba97c00a713c217124420147681a2f/mako-1.3.10-py3-none-any.whl.metadata\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from cryptography<46,>=43.0.0->mlflow) (1.15.1)\n",
      "Requirement already satisfied: google-auth~=2.0 in c:\\users\\nnassili\\appdata\\roaming\\python\\python311\\site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow) (2.41.1)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\programdata\\anaconda3\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (305.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (1.26.16)\n",
      "Collecting authlib>=1.5.2 (from fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for authlib>=1.5.2 from https://files.pythonhosted.org/packages/f8/aa/5082412d1ee302e9e7d80b6949bc4d2a8fa1149aaab610c5fc24709605d6/authlib-1.6.5-py2.py3-none-any.whl.metadata\n",
      "  Downloading authlib-1.6.5-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting cyclopts>=3.0.0 (from fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for cyclopts>=3.0.0 from https://files.pythonhosted.org/packages/f0/8b/2c95f0645c6f40211896375e6fa51f504b8ccb29c21f6ae661fe87ab044e/cyclopts-3.24.0-py3-none-any.whl.metadata\n",
      "  Downloading cyclopts-3.24.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting exceptiongroup>=1.2.2 (from fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for exceptiongroup>=1.2.2 from https://files.pythonhosted.org/packages/36/f4/c6e662dade71f56cd2f3735141b265c3c79293c109549c1e6933b0651ffc/exceptiongroup-1.3.0-py3-none-any.whl.metadata\n",
      "  Downloading exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting httpx>=0.28.1 (from fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for httpx>=0.28.1 from https://files.pythonhosted.org/packages/2a/39/e50c7c3a983047577ee07d2a9e53faf5a69493943ec3f6a384bdc792deb2/httpx-0.28.1-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting mcp<2.0.0,>=1.12.4 (from fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for mcp<2.0.0,>=1.12.4 from https://files.pythonhosted.org/packages/1c/72/3751feae343a5ad07959df713907b5c3fbaed269d697a14b0c449080cf2e/mcp-1.17.0-py3-none-any.whl.metadata\n",
      "  Downloading mcp-1.17.0-py3-none-any.whl.metadata (80 kB)\n",
      "     ---------------------------------------- 0.0/80.3 kB ? eta -:--:--\n",
      "     -------------------- ------------------- 41.0/80.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 80.3/80.3 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting openapi-core>=0.19.5 (from fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for openapi-core>=0.19.5 from https://files.pythonhosted.org/packages/27/6f/83ead0e2e30a90445ee4fc0135f43741aebc30cca5b43f20968b603e30b6/openapi_core-0.19.5-py3-none-any.whl.metadata\n",
      "  Downloading openapi_core-0.19.5-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting openapi-pydantic>=0.5.1 (from fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for openapi-pydantic>=0.5.1 from https://files.pythonhosted.org/packages/12/cf/03675d8bd8ecbf4445504d8071adab19f5f993676795708e36402ab38263/openapi_pydantic-0.5.1-py3-none-any.whl.metadata\n",
      "  Downloading openapi_pydantic-0.5.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pydantic[email]>=2.11.7 (from fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for pydantic[email]>=2.11.7 from https://files.pythonhosted.org/packages/6c/98/468cb649f208a6f1279448e6e5247b37ae79cf5e4041186f1e2ef3d16345/pydantic-2.12.2-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.12.2-py3-none-any.whl.metadata (85 kB)\n",
      "     ---------------------------------------- 0.0/85.8 kB ? eta -:--:--\n",
      "     -------------------------------------- - 81.9/85.8 kB 1.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 85.8/85.8 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting pyperclip>=1.9.0 (from fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for pyperclip>=1.9.0 from https://files.pythonhosted.org/packages/df/80/fc9d01d5ed37ba4c42ca2b55b4339ae6e200b456be3a1aaddf4a9fa99b8c/pyperclip-1.11.0-py3-none-any.whl.metadata\n",
      "  Downloading pyperclip-1.11.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting python-dotenv<2,>=0.19.0 (from mlflow-skinny==3.4.0->mlflow)\n",
      "  Obtaining dependency information for python-dotenv<2,>=0.19.0 from https://files.pythonhosted.org/packages/5f/ed/539768cf28c661b5b068d66d96a2f155c4971a5d55684a514c1a0e0dec2f/python_dotenv-1.1.1-py3-none-any.whl.metadata\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting rich>=13.9.4 (from fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for rich>=13.9.4 from https://files.pythonhosted.org/packages/25/7a/b0178788f8dc6cafce37a212c99565fa1fe7872c70c6c9c1e1a372d9d88f/rich-14.2.0-py3-none-any.whl.metadata\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask<4->mlflow) (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask<4->mlflow) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask<4->mlflow) (2.0.1)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Obtaining dependency information for graphql-core<3.3,>=3.1 from https://files.pythonhosted.org/packages/ae/4f/7297663840621022bc73c22d7d9d80dbc78b4db6297f764b545cd5dd462d/graphql_core-3.2.6-py3-none-any.whl.metadata\n",
      "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Obtaining dependency information for graphql-relay<3.3,>=3.1 from https://files.pythonhosted.org/packages/74/16/a4cf06adbc711bd364a73ce043b0b08d8fa5aae3df11b6ee4248bcdad2e0/graphql_relay-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from graphene<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas<3->mlflow) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas<3->mlflow) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn<2->mlflow) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn<2->mlflow) (2.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (2.0.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->cryptography<46,>=43.0.0->mlflow) (2.21)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click<9,>=7.0->mlflow-skinny==3.4.0->mlflow) (0.4.6)\n",
      "Collecting attrs>=23.1.0 (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for attrs>=23.1.0 from https://files.pythonhosted.org/packages/3a/2a/7cc015f5b9f5db42b7d48157e23356022889fc354a2813c15934b7cb5c0e/attrs-25.4.0-py3-none-any.whl.metadata\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting docstring-parser>=0.15 (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for docstring-parser>=0.15 from https://files.pythonhosted.org/packages/55/e2/2537ebcff11c1ee1ff17d8d0b6f4db75873e3b0fb32c2d4a2ee31ecb310a/docstring_parser-0.17.0-py3-none-any.whl.metadata\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich-rst<2.0.0,>=1.3.1 (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for rich-rst<2.0.0,>=1.3.1 from https://files.pythonhosted.org/packages/13/2f/b4530fbf948867702d0a3f27de4a6aab1d156f406d72852ab902c4d04de9/rich_rst-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading rich_rst-1.3.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting starlette<0.49.0,>=0.40.0 (from fastapi<1->mlflow-skinny==3.4.0->mlflow)\n",
      "  Obtaining dependency information for starlette<0.49.0,>=0.40.0 from https://files.pythonhosted.org/packages/be/72/2db2f49247d0a18b4f1bb9a5a39a0162869acf235f3a96418363947b3d46/starlette-0.48.0-py3-none-any.whl.metadata\n",
      "  Downloading starlette-0.48.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==3.4.0->mlflow)\n",
      "  Obtaining dependency information for gitdb<5,>=4.0.1 from https://files.pythonhosted.org/packages/a0/61/5c78b91c3143ed5c14207f463aecfc8f9dbb5092fb2869baf37c273b2705/gitdb-4.0.12-py3-none-any.whl.metadata\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\nnassili\\appdata\\roaming\\python\\python311\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow) (4.9.1)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow) (3.5.0)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow) (2023.7.22)\n",
      "Collecting httpcore==1.* (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/7e/f5/f66802a942d491edb555dd61e3a9961140fd64c90bce1eafd741609d334d/httpcore-1.0.9-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow) (3.4)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for h11>=0.16 from https://files.pythonhosted.org/packages/04/4b/29cac41a4d98d144bf5f6d33995617b185d14b22401f75ca86f384e87ff1/h11-0.16.0-py3-none-any.whl.metadata\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.4.0->mlflow) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Jinja2>=3.0->Flask<4->mlflow) (2.1.1)\n",
      "Collecting anyio (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for anyio from https://files.pythonhosted.org/packages/15/b3/9b1a8074496371342ec1e796a96f99c82c945a339cd81a8e73de28b4cf9e/anyio-4.11.0-py3-none-any.whl.metadata\n",
      "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting httpx-sse>=0.4 (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for httpx-sse>=0.4 from https://files.pythonhosted.org/packages/d2/fd/6668e5aec43ab844de6fc74927e155a3b37bf40d7c3790e49fc0406b6578/httpx_sse-0.4.3-py3-none-any.whl.metadata\n",
      "  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting jsonschema>=4.20.0 (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for jsonschema>=4.20.0 from https://files.pythonhosted.org/packages/bf/9c/8c95d856233c1f82500c2450b8c68576b4cf1c871db3afac5c34ff84e6fd/jsonschema-4.25.1-py3-none-any.whl.metadata\n",
      "  Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pydantic-settings>=2.5.2 (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for pydantic-settings>=2.5.2 from https://files.pythonhosted.org/packages/83/d6/887a1ff844e64aa823fb4905978d882a633cfe295c32eacad582b78a7d8b/pydantic_settings-2.11.0-py3-none-any.whl.metadata\n",
      "  Downloading pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for python-multipart>=0.0.9 from https://files.pythonhosted.org/packages/45/58/38b5afbc1a800eeea951b9285d3912613f2603bdf897a4ab0f4bd7f405fc/python_multipart-0.0.20-py3-none-any.whl.metadata\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pywin32>=304 (from docker<8,>=4.0.0->mlflow)\n",
      "  Obtaining dependency information for pywin32>=304 from https://files.pythonhosted.org/packages/51/8f/9bb81dd5bb77d22243d33c8397f09377056d5c687aa6d4042bea7fbf8364/pywin32-311-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading pywin32-311-cp311-cp311-win_amd64.whl.metadata (10 kB)\n",
      "Collecting sse-starlette>=1.6.1 (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for sse-starlette>=1.6.1 from https://files.pythonhosted.org/packages/ef/10/c78f463b4ef22eef8491f218f692be838282cd65480f6e423d7730dfd1fb/sse_starlette-3.0.2-py3-none-any.whl.metadata\n",
      "  Downloading sse_starlette-3.0.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting isodate (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for isodate from https://files.pythonhosted.org/packages/15/aa/0aca39a37d3c7eb941ba736ede56d689e7be91cab5d9ca846bde3999eba6/isodate-0.7.2-py3-none-any.whl.metadata\n",
      "  Using cached isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jsonschema-path<0.4.0,>=0.3.1 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for jsonschema-path<0.4.0,>=0.3.1 from https://files.pythonhosted.org/packages/cb/58/3485da8cb93d2f393bce453adeef16896751f14ba3e2024bc21dc9597646/jsonschema_path-0.3.4-py3-none-any.whl.metadata\n",
      "  Downloading jsonschema_path-0.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: more-itertools in c:\\programdata\\anaconda3\\lib\\site-packages (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow) (8.12.0)\n",
      "Collecting openapi-schema-validator<0.7.0,>=0.6.0 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for openapi-schema-validator<0.7.0,>=0.6.0 from https://files.pythonhosted.org/packages/21/c6/ad0fba32775ae749016829dace42ed80f4407b171da41313d1a3a5f102e4/openapi_schema_validator-0.6.3-py3-none-any.whl.metadata\n",
      "  Downloading openapi_schema_validator-0.6.3-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting openapi-spec-validator<0.8.0,>=0.7.1 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for openapi-spec-validator<0.8.0,>=0.7.1 from https://files.pythonhosted.org/packages/27/dd/b3fd642260cb17532f66cc1e8250f3507d1e580483e209dc1e9d13bd980d/openapi_spec_validator-0.7.2-py3-none-any.whl.metadata\n",
      "  Downloading openapi_spec_validator-0.7.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting parse (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for parse from https://files.pythonhosted.org/packages/d0/31/ba45bf0b2aa7898d81cbbfac0e88c267befb59ad91a19e36e1bc5578ddb1/parse-1.20.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.58b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.4.0->mlflow)\n",
      "  Obtaining dependency information for opentelemetry-semantic-conventions==0.58b0 from https://files.pythonhosted.org/packages/07/90/68152b7465f50285d3ce2481b3aec2f82822e3f52e5152eeeaf516bab841/opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for annotated-types>=0.6.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for pydantic-core==2.41.4 from https://files.pythonhosted.org/packages/e0/9d/7c5e24ee585c1f8b6356e1d11d40ab807ffde44d2db3b7dfd6d20b09720e/pydantic_core-2.41.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading pydantic_core-2.41.4-cp311-cp311-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for typing-inspection>=0.4.2 from https://files.pythonhosted.org/packages/dc/9b/47798a6c91d8bdb567fe2698fe81e0c6b7cb7ef4d13da4114b41d239f65d/typing_inspection-0.4.2-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting email-validator>=2.0.0 (from pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for email-validator>=2.0.0 from https://files.pythonhosted.org/packages/de/15/545e2b6cf2e3be84bc1ed85613edd75b8aea69807a71c26f4ca6a9258e82/email_validator-2.3.0-py3-none-any.whl.metadata\n",
      "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.4.0->mlflow) (2.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow) (2.15.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow) (1.2.0)\n",
      "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for dnspython>=2.0.0 from https://files.pythonhosted.org/packages/ba/5a/18ad964b0086c6e62e2e7500f7edc89e3faa45033c71c1893d34eed2b2de/dnspython-2.8.0-py3-none-any.whl.metadata\n",
      "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.4.0->mlflow)\n",
      "  Obtaining dependency information for smmap<6,>=3.0.1 from https://files.pythonhosted.org/packages/04/be/d09147ad1ec7934636ad912901c5fd7667e1c858e19d355237db0d0cd5e4/smmap-5.0.2-py3-none-any.whl.metadata\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for jsonschema-specifications>=2023.03.6 from https://files.pythonhosted.org/packages/41/45/1a4ed80516f02155c51f51e8cedb3c1902296743db0bbc66608a0db2814f/jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata\n",
      "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for referencing>=0.28.4 from https://files.pythonhosted.org/packages/2c/58/ca301544e1fa93ed4f80d724bf5b194f6e4b945841c5bfd555878eea9fcb/referencing-0.37.0-py3-none-any.whl.metadata\n",
      "  Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for rpds-py>=0.7.1 from https://files.pythonhosted.org/packages/24/75/3b7ffe0d50dc86a6a964af0d1cc3a4a2cdf437cb7b099a4747bbb96d1819/rpds_py-0.27.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached rpds_py-0.27.1-cp311-cp311-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path<0.4.0,>=0.3.1->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for pathable<0.5.0,>=0.4.1 from https://files.pythonhosted.org/packages/7d/eb/b6260b31b1a96386c0a880edebe26f89669098acea8e0318bff6adb378fd/pathable-0.4.4-py3-none-any.whl.metadata\n",
      "  Downloading pathable-0.4.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for referencing>=0.28.4 from https://files.pythonhosted.org/packages/c1/b1/3baf80dc6d2b7bc27a95a67752d0208e410351e3feb4eb78de5f77454d8d/referencing-0.36.2-py3-none-any.whl.metadata\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow) (0.1.0)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\programdata\\anaconda3\\lib\\site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow) (0.1.4)\n",
      "Collecting lazy-object-proxy<2.0.0,>=1.7.1 (from openapi-spec-validator<0.8.0,>=0.7.1->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
      "  Obtaining dependency information for lazy-object-proxy<2.0.0,>=1.7.1 from https://files.pythonhosted.org/packages/6a/48/4b718c937004bf71cd82af3713874656bcb8d0cc78600bf33bb9619adc6c/lazy_object_proxy-1.12.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading lazy_object_proxy-1.12.0-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow) (0.4.8)\n",
      "Requirement already satisfied: docutils in c:\\programdata\\anaconda3\\lib\\site-packages (from rich-rst<2.0.0,>=1.3.1->cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow) (0.18.1)\n",
      "Downloading mlflow-3.4.0-py3-none-any.whl (26.7 MB)\n",
      "   ---------------------------------------- 0.0/26.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/26.7 MB 4.2 MB/s eta 0:00:07\n",
      "    --------------------------------------- 0.4/26.7 MB 4.1 MB/s eta 0:00:07\n",
      "    --------------------------------------- 0.7/26.7 MB 4.6 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 1.0/26.7 MB 5.6 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.5/26.7 MB 6.9 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 1.9/26.7 MB 7.3 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 2.5/26.7 MB 7.9 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 3.1/26.7 MB 8.5 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 3.3/26.7 MB 8.7 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 3.3/26.7 MB 8.7 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 3.3/26.7 MB 8.7 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.2/26.7 MB 8.2 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.2/26.7 MB 8.2 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.6/26.7 MB 7.3 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 5.2/26.7 MB 7.7 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 5.8/26.7 MB 8.0 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 6.3/26.7 MB 8.2 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 6.8/26.7 MB 8.4 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 7.3/26.7 MB 8.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 7.7/26.7 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 8.3/26.7 MB 8.8 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 9.0/26.7 MB 8.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 9.5/26.7 MB 9.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 10.1/26.7 MB 9.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 10.5/26.7 MB 9.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 11.0/26.7 MB 9.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 11.7/26.7 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.2/26.7 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.6/26.7 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 13.1/26.7 MB 9.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 13.7/26.7 MB 11.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 14.3/26.7 MB 10.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.8/26.7 MB 11.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 15.3/26.7 MB 11.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 16.0/26.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 16.5/26.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 17.0/26.7 MB 11.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 17.5/26.7 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 18.2/26.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.8/26.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 19.3/26.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 19.8/26.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 20.3/26.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.8/26.7 MB 11.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.4/26.7 MB 11.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.9/26.7 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 22.5/26.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 23.1/26.7 MB 11.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.5/26.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.1/26.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.6/26.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 25.2/26.7 MB 11.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.7/26.7 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.3/26.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.7/26.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.7/26.7 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.7/26.7 MB 10.1 MB/s eta 0:00:00\n",
      "Downloading mlflow_skinny-3.4.0-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.6/2.2 MB 19.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.2 MB 14.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.2 MB 14.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.5/2.2 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 10.9 MB/s eta 0:00:00\n",
      "Downloading mlflow_tracing-3.4.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.2 MB 5.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.7/1.2 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.1/1.2 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading alembic-1.17.0-py3-none-any.whl (247 kB)\n",
      "   ---------------------------------------- 0.0/247.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 247.4/247.4 kB 15.8 MB/s eta 0:00:00\n",
      "Using cached cryptography-45.0.7-cp311-abi3-win_amd64.whl (3.4 MB)\n",
      "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "   ---------------------------------------- 0.0/147.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 147.8/147.8 kB ? eta 0:00:00\n",
      "Downloading fastmcp-2.12.4-py3-none-any.whl (329 kB)\n",
      "   ---------------------------------------- 0.0/329.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 329.1/329.1 kB 21.3 MB/s eta 0:00:00\n",
      "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "   ---------------------------------------- 0.0/114.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 114.9/114.9 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading waitress-3.0.2-py3-none-any.whl (56 kB)\n",
      "   ---------------------------------------- 0.0/56.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 56.2/56.2 kB ? eta 0:00:00\n",
      "Downloading authlib-1.6.5-py2.py3-none-any.whl (243 kB)\n",
      "   ---------------------------------------- 0.0/243.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 243.6/243.6 kB 7.3 MB/s eta 0:00:00\n",
      "Downloading cyclopts-3.24.0-py3-none-any.whl (86 kB)\n",
      "   ---------------------------------------- 0.0/86.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 86.2/86.2 kB ? eta 0:00:00\n",
      "Downloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\n",
      "Downloading fastapi-0.119.0-py3-none-any.whl (107 kB)\n",
      "   ---------------------------------------- 0.0/107.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 107.1/107.1 kB 6.1 MB/s eta 0:00:00\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "   ---------------------------------------- 0.0/208.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 208.2/208.2 kB 12.4 MB/s eta 0:00:00\n",
      "Downloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
      "   ---------------------------------------- 0.0/203.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 203.4/203.4 kB 12.1 MB/s eta 0:00:00\n",
      "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "   ---------------------------------------- 0.0/73.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 73.5/73.5 kB ? eta 0:00:00\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.8/78.8 kB ? eta 0:00:00\n",
      "Downloading mcp-1.17.0-py3-none-any.whl (167 kB)\n",
      "   ---------------------------------------- 0.0/167.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 167.7/167.7 kB 9.8 MB/s eta 0:00:00\n",
      "Downloading openapi_core-0.19.5-py3-none-any.whl (106 kB)\n",
      "   ---------------------------------------- 0.0/106.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 106.6/106.6 kB ? eta 0:00:00\n",
      "Downloading openapi_pydantic-0.5.1-py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.4/96.4 kB 5.7 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 0.0/65.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 65.7/65.7 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
      "   ---------------------------------------- 0.0/72.5 kB ? eta -:--:--\n",
      "   ---------------------------------------  71.7/72.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 72.5/72.5 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n",
      "   ---------------------------------------- 0.0/131.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 131.9/131.9 kB 7.6 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n",
      "   ---------------------------------------- 0.0/208.0 kB ? eta -:--:--\n",
      "   ----------------------------- ---------- 153.6/208.0 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 194.6/208.0 kB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 194.6/208.0 kB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 194.6/208.0 kB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 194.6/208.0 kB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 194.6/208.0 kB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 194.6/208.0 kB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 194.6/208.0 kB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 194.6/208.0 kB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- 208.0/208.0 kB 468.5 kB/s eta 0:00:00\n",
      "Downloading pydantic-2.12.2-py3-none-any.whl (460 kB)\n",
      "   ---------------------------------------- 0.0/460.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/460.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/460.6 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/460.6 kB ? eta -:--:--\n",
      "   - ------------------------------------- 20.5/460.6 kB 222.6 kB/s eta 0:00:02\n",
      "   -- ------------------------------------ 30.7/460.6 kB 445.2 kB/s eta 0:00:01\n",
      "   --- ----------------------------------- 41.0/460.6 kB 330.3 kB/s eta 0:00:02\n",
      "   ----- --------------------------------- 61.4/460.6 kB 365.7 kB/s eta 0:00:02\n",
      "   ------ -------------------------------- 71.7/460.6 kB 328.6 kB/s eta 0:00:02\n",
      "   ------- ------------------------------- 92.2/460.6 kB 350.1 kB/s eta 0:00:02\n",
      "   ---------- --------------------------- 122.9/460.6 kB 400.9 kB/s eta 0:00:01\n",
      "   ------------ ------------------------- 153.6/460.6 kB 437.1 kB/s eta 0:00:01\n",
      "   ---------------- --------------------- 194.6/460.6 kB 491.5 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 225.3/460.6 kB 510.8 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 256.0/460.6 kB 542.5 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 286.7/460.6 kB 553.0 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 337.9/460.6 kB 600.1 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 389.1/460.6 kB 638.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- 460.6/460.6 kB 686.6 kB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.41.4-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/2.0 MB 2.4 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.2/2.0 MB 1.7 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.3/2.0 MB 1.8 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.5/2.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.6/2.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/2.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.9/2.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.0 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.1/2.0 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.0 MB 2.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.4/2.0 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.6/2.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/2.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 2.3 MB/s eta 0:00:00\n",
      "Downloading pyperclip-1.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading pywin32-311-cp311-cp311-win_amd64.whl (9.5 MB)\n",
      "   ---------------------------------------- 0.0/9.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/9.5 MB 4.6 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.4/9.5 MB 4.5 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.5/9.5 MB 3.7 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.7/9.5 MB 3.8 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.9/9.5 MB 3.9 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.1/9.5 MB 4.0 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.3/9.5 MB 3.9 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.4/9.5 MB 4.1 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.6/9.5 MB 3.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.8/9.5 MB 4.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.0/9.5 MB 4.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.3/9.5 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.5/9.5 MB 4.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.7/9.5 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.9/9.5 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.1/9.5 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.4/9.5 MB 4.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.6/9.5 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.8/9.5 MB 4.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.1/9.5 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.3/9.5 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.6/9.5 MB 4.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.8/9.5 MB 4.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.1/9.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.4/9.5 MB 4.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.6/9.5 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.9/9.5 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.1/9.5 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.3/9.5 MB 4.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.6/9.5 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.0/9.5 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.2/9.5 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.5/9.5 MB 5.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.9/9.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.2/9.5 MB 5.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.4/9.5 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.7/9.5 MB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.1/9.5 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.3/9.5 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.5/9.5 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.5/9.5 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "   ---------------------------------------- 0.0/243.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 243.4/243.4 kB 14.6 MB/s eta 0:00:00\n",
      "Using cached sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Downloading uvicorn-0.37.0-py3-none-any.whl (67 kB)\n",
      "   ---------------------------------------- 0.0/68.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 68.0/68.0 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB ? eta 0:00:00\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "   ---------------------------------------- 0.0/109.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 109.1/109.1 kB ? eta 0:00:00\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "   ---------------------------------------- 0.0/67.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 67.6/67.6 kB ? eta 0:00:00\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.8/62.8 kB ? eta 0:00:00\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Downloading jsonschema_path-0.3.4-py3-none-any.whl (14 kB)\n",
      "Downloading openapi_schema_validator-0.6.3-py3-none-any.whl (8.8 kB)\n",
      "Downloading openapi_spec_validator-0.7.2-py3-none-any.whl (39 kB)\n",
      "Downloading pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
      "   ---------------------------------------- 0.0/48.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 48.6/48.6 kB ? eta 0:00:00\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading rich_rst-1.3.2-py3-none-any.whl (12 kB)\n",
      "Downloading sse_starlette-3.0.2-py3-none-any.whl (11 kB)\n",
      "Downloading starlette-0.48.0-py3-none-any.whl (73 kB)\n",
      "   ---------------------------------------- 0.0/73.7 kB ? eta -:--:--\n",
      "   ---------------------- ----------------- 41.0/73.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 73.7/73.7 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Downloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
      "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
      "   ---------------------------------------- 0.0/331.1 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 92.2/331.1 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 286.7/331.1 kB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 331.1/331.1 kB 2.6 MB/s eta 0:00:00\n",
      "Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Downloading lazy_object_proxy-1.12.0-cp311-cp311-win_amd64.whl (26 kB)\n",
      "Downloading pathable-0.4.4-py3-none-any.whl (9.6 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Using cached rpds_py-0.27.1-cp311-cp311-win_amd64.whl (228 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pywin32, pyperclip, parse, waitress, typing-inspection, sqlparse, smmap, rpds-py, python-multipart, python-dotenv, pydantic-core, pathable, opentelemetry-proto, Mako, lazy-object-proxy, isodate, httpx-sse, h11, graphql-core, exceptiongroup, docstring-parser, dnspython, attrs, anyio, annotated-types, uvicorn, starlette, sse-starlette, rich, referencing, pydantic, opentelemetry-api, httpcore, graphql-relay, gitdb, email-validator, docker, cryptography, alembic, rich-rst, pydantic-settings, opentelemetry-semantic-conventions, openapi-pydantic, jsonschema-specifications, jsonschema-path, httpx, graphene, gitpython, fastapi, authlib, opentelemetry-sdk, jsonschema, cyclopts, openapi-schema-validator, mlflow-tracing, mlflow-skinny, mcp, openapi-spec-validator, openapi-core, fastmcp, mlflow\n",
      "Successfully installed Mako-1.3.10 alembic-1.17.0 annotated-types-0.7.0 anyio-4.11.0 attrs-25.4.0 authlib-1.6.5 cryptography-45.0.7 cyclopts-3.24.0 dnspython-2.8.0 docker-7.1.0 docstring-parser-0.17.0 email-validator-2.3.0 exceptiongroup-1.3.0 fastapi-0.119.0 fastmcp-2.12.4 gitdb-4.0.12 gitpython-3.1.45 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.3 isodate-0.7.2 jsonschema-4.25.1 jsonschema-path-0.3.4 jsonschema-specifications-2025.9.1 lazy-object-proxy-1.12.0 mcp-1.17.0 mlflow-3.4.0 mlflow-skinny-3.4.0 mlflow-tracing-3.4.0 openapi-core-0.19.5 openapi-pydantic-0.5.1 openapi-schema-validator-0.6.3 openapi-spec-validator-0.7.2 opentelemetry-api-1.37.0 opentelemetry-proto-1.37.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0 parse-1.20.2 pathable-0.4.4 pydantic-2.12.2 pydantic-core-2.41.4 pydantic-settings-2.11.0 pyperclip-1.11.0 python-dotenv-1.1.1 python-multipart-0.0.20 pywin32-311 referencing-0.36.2 rich-14.2.0 rich-rst-1.3.2 rpds-py-0.27.1 smmap-5.0.2 sqlparse-0.5.3 sse-starlette-3.0.2 starlette-0.48.0 typing-inspection-0.4.2 uvicorn-0.37.0 waitress-3.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts pywin32_postinstall.exe and pywin32_testall.exe are installed in 'C:\\Users\\nnassili\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script waitress-serve.exe is installed in 'C:\\Users\\nnassili\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script sqlformat.exe is installed in 'C:\\Users\\nnassili\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script dotenv.exe is installed in 'C:\\Users\\nnassili\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script mako-render.exe is installed in 'C:\\Users\\nnassili\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script uvicorn.exe is installed in 'C:\\Users\\nnassili\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script email_validator.exe is installed in 'C:\\Users\\nnassili\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script alembic.exe is installed in 'C:\\Users\\nnassili\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script httpx.exe is installed in 'C:\\Users\\nnassili\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script fastapi.exe is installed in 'C:\\Users\\nnassili\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jsonschema.exe is installed in 'C:\\Users\\nnassili\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script mlflow.exe is installed in 'C:\\Users\\nnassili\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script mcp.exe is installed in 'C:\\Users\\nnassili\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script openapi-spec-validator.exe is installed in 'C:\\Users\\nnassili\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script fastmcp.exe is installed in 'C:\\Users\\nnassili\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script mlflow.exe is installed in 'C:\\Users\\nnassili\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-cloud-auth 0.1.3 requires pydantic<2.0, but you have pydantic 2.12.2 which is incompatible.\n",
      "jupyter-server 1.23.4 requires anyio<4,>=3.1.0, but you have anyio 4.11.0 which is incompatible.\n",
      "pyopenssl 23.2.0 requires cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0, but you have cryptography 45.0.7 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Optional: ensure required packages are present in the current environment\n",
    "# !pip install --quiet mlflow databricks-connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bcfadf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "databricks-connect version: unknown\n",
      "Found configuration file: C:\\Users\\nnassili\\.databricks-connect\n",
      "Config preview (first 400 chars):\n",
      "{\n",
      "  \"host\": \"https://dbc-935124bd-e5fd.cloud.databricks.com/\",\n",
      "  \"token\": \"YOUR_DATABRICKS_TOKEN\",\n",
      "  \"org_id\": \"0\",\n",
      "  \"port\": \"15001\",\n",
      "  \"http_path\": \"/sql/1.0/warehouses/7bb142c4f4ff862e\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: ensure databricks-connect package is available and show config location\n",
    "import importlib, json, os, pathlib\n",
    "DESIRED_HTTP_PATH = os.getenv('DATABRICKS_HTTP_PATH', '/sql/1.0/warehouses/7bb142c4f4ff862e')\n",
    "try:\n",
    "    dbc_module = importlib.import_module('databricks.connect')\n",
    "    print('databricks-connect version:', getattr(dbc_module, '__version__', 'unknown'))\n",
    "    config_path = pathlib.Path.home() / '.databricks-connect'\n",
    "    if config_path.exists():\n",
    "        print('Found configuration file:', config_path)\n",
    "        try:\n",
    "            config_text = config_path.read_text()\n",
    "            print('Config preview (first 400 chars):')\n",
    "            print(config_text[:400])\n",
    "            config_json = json.loads(config_text)\n",
    "            updated = False\n",
    "            if config_json.get('http_path') != DESIRED_HTTP_PATH:\n",
    "                config_json['http_path'] = DESIRED_HTTP_PATH\n",
    "                updated = True\n",
    "            if config_json.pop('cluster_id', None) is not None:\n",
    "                updated = True\n",
    "            if updated:\n",
    "                backup_path = config_path.with_suffix('.bak')\n",
    "                backup_path.write_text(config_text)\n",
    "                config_path.write_text(json.dumps(config_json, indent=2))\n",
    "                print(f'Updated ~/.databricks-connect and saved backup to {backup_path}.')\n",
    "            os.environ.setdefault('DATABRICKS_HTTP_PATH', config_json.get('http_path', DESIRED_HTTP_PATH))\n",
    "        except Exception as read_err:\n",
    "            print('Could not read/update config file:', read_err)\n",
    "    else:\n",
    "        print('No ~/.databricks-connect file detected; run `databricks-connect configure`.')\n",
    "    databricks_connect_ok = True\n",
    "except ModuleNotFoundError:\n",
    "    databricks_connect_ok = False\n",
    "    print('databricks-connect package is not installed. Run `pip install databricks-connect`.')\n",
    "except Exception as e:\n",
    "    databricks_connect_ok = False\n",
    "    print('databricks-connect check error:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9720d907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n",
      "OS: Windows-10-10.0.26100-SP0\n",
      "CWD: c:\\Users\\nnassili\\Documents\\life-style-mlops\\notebooks\n",
      "GRPC_DEFAULT_SSL_ROOTS_FILE_PATH: c:\\ProgramData\\anaconda3\\Lib\\site-packages\\certifi\\cacert.pem\n",
      "SSL_CERT_FILE: C:\\ProgramData\\anaconda3\\Library\\ssl\\cacert.pem\n",
      "NO_PROXY: dbc-935124bd-e5fd.cloud.databricks.com,.databricks.com\n",
      "DATABRICKS_HOST: https://dbc-935124bd-e5fd.cloud.databricks.com\n",
      "DATABRICKS_TOKEN prefix: dapi09f2...\n",
      "DATABRICKS_CLUSTER_ID: None\n",
      "WAREHOUSE/SERVERLESS ID: auto\n",
      "HTTP_PATH: /sql/1.0/warehouses/7bb142c4f4ff862e\n"
     ]
    }
   ],
   "source": [
    "# Setup: env, SSL certs, and basic validation\n",
    "from dotenv import load_dotenv\n",
    "import os, sys, certifi, platform, urllib.parse\n",
    "load_dotenv()\n",
    "os.environ[\"GRPC_DEFAULT_SSL_ROOTS_FILE_PATH\"] = certifi.where()\n",
    "os.environ.setdefault(\"SSL_CERT_FILE\", certifi.where())\n",
    "host = os.getenv('DATABRICKS_HOST')\n",
    "token = os.getenv('DATABRICKS_TOKEN')\n",
    "cluster_id = os.getenv('DATABRICKS_CLUSTER_ID')\n",
    "warehouse_id = os.getenv('DATABRICKS_WAREHOUSE_ID') or os.getenv('DATABRICKS_SERVERLESS_COMPUTE_ID')\n",
    "http_path = os.getenv('DATABRICKS_HTTP_PATH') or os.getenv('DATABRICKS_SQL_HTTP_PATH')\n",
    "# Derive host domain and set NO_PROXY to avoid corporate proxy breaking gRPC\n",
    "try:\n",
    "    parsed = urllib.parse.urlparse(host) if host else None\n",
    "    domain = parsed.hostname if parsed else None\n",
    "    if domain:\n",
    "        existing_no_proxy = os.environ.get('NO_PROXY', '')\n",
    "        tokens = [t.strip() for t in existing_no_proxy.split(',') if t.strip()]\n",
    "        if domain not in tokens:\n",
    "            tokens.append(domain)\n",
    "        if '.databricks.com' not in tokens:\n",
    "            tokens.append('.databricks.com')\n",
    "        os.environ['NO_PROXY'] = ','.join(tokens)\n",
    "except Exception:\n",
    "    pass\n",
    "print('Python:', sys.version)\n",
    "print('OS:', platform.platform())\n",
    "print('CWD:', os.getcwd())\n",
    "print('GRPC_DEFAULT_SSL_ROOTS_FILE_PATH:', os.environ.get('GRPC_DEFAULT_SSL_ROOTS_FILE_PATH'))\n",
    "print('SSL_CERT_FILE:', os.environ.get('SSL_CERT_FILE'))\n",
    "print('NO_PROXY:', os.environ.get('NO_PROXY'))\n",
    "print('DATABRICKS_HOST:', host)\n",
    "print('DATABRICKS_TOKEN prefix:', (token[:8] + '...') if token else None)\n",
    "print('DATABRICKS_CLUSTER_ID:', cluster_id)\n",
    "print('WAREHOUSE/SERVERLESS ID:', warehouse_id)\n",
    "print('HTTP_PATH:', http_path)\n",
    "if not host or not token:\n",
    "    print('ERROR: Missing DATABRICKS_HOST or DATABRICKS_TOKEN in .env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee3e7162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISABLE_SSL_VERIFY set for this session. Remove when corporate CA bundle is available.\n"
     ]
    }
   ],
   "source": [
    "# TEMP: disable TLS verification until corporate CA is installed\n",
    "import os\n",
    "os.environ['DISABLE_SSL_VERIFY'] = '1'\n",
    "print('DISABLE_SSL_VERIFY set for this session. Remove when corporate CA bundle is available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0f046c",
   "metadata": {},
   "source": [
    "## Optional SSL/proxy override (debug only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe52428",
   "metadata": {},
   "source": [
    "## Corporate CA merge (Spark Connect TLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed3d5080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set CORPORATE_CA_BUNDLE (or EXTRA_CA_CERTS) env var to a PEM file with corporate roots if gRPC TLS fails.\n"
     ]
    }
   ],
   "source": [
    "# Merge corporate CA bundle (if provided) with certifi for Spark Connect TLS\n",
    "import os, certifi, tempfile\n",
    "from pathlib import Path\n",
    "combined_ca_bundle = None\n",
    "custom_ca_env = os.getenv('CORPORATE_CA_BUNDLE') or os.getenv('EXTRA_CA_CERTS')\n",
    "if custom_ca_env:\n",
    "    custom_ca_path = Path(custom_ca_env).expanduser()\n",
    "    if custom_ca_path.exists():\n",
    "        combined_ca_bundle = Path(tempfile.gettempdir()) / 'databricks_connect_combined_ca.pem'\n",
    "        try:\n",
    "            with open(certifi.where(), 'rb') as base, open(custom_ca_path, 'rb') as extra, open(combined_ca_bundle, 'wb') as out:\n",
    "                out.write(base.read())\n",
    "                out.write(b\"\\n\")\n",
    "                out.write(extra.read())\n",
    "            os.environ['GRPC_DEFAULT_SSL_ROOTS_FILE_PATH'] = str(combined_ca_bundle)\n",
    "            os.environ['SSL_CERT_FILE'] = str(combined_ca_bundle)\n",
    "            os.environ['REQUESTS_CA_BUNDLE'] = str(combined_ca_bundle)\n",
    "            os.environ['CURL_CA_BUNDLE'] = str(combined_ca_bundle)\n",
    "            print('Combined CA bundle applied:', combined_ca_bundle)\n",
    "        except Exception as ca_err:\n",
    "            combined_ca_bundle = None\n",
    "            print('Could not merge corporate CA bundle:', ca_err)\n",
    "    else:\n",
    "        print('Corporate CA path not found:', custom_ca_path)\n",
    "        print('Provide a PEM file containing your organization\\'s root certificates (see Spark Connect TLS guidance).')\n",
    "else:\n",
    "    print('Set CORPORATE_CA_BUNDLE (or EXTRA_CA_CERTS) env var to a PEM file with corporate roots if gRPC TLS fails.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "535934a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nnassili\\AppData\\Local\\Temp\\ipykernel_14440\\3121462269.py:4: RuntimeWarning: SSL verification disabled  use only for local debugging.\n",
      "  warnings.warn('SSL verification disabled  use only for local debugging.', RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import ssl, warnings, os\n",
    "DISABLE_SSL_VERIFY = os.getenv('DISABLE_SSL_VERIFY', 'False').lower() in ('1', 'true', 'yes')\n",
    "if DISABLE_SSL_VERIFY:\n",
    "    warnings.warn('SSL verification disabled  use only for local debugging.', RuntimeWarning)\n",
    "    os.environ['GRPC_DEFAULT_SSL_ROOTS_FILE_PATH'] = ''\n",
    "    os.environ['SSL_CERT_FILE'] = ''\n",
    "    os.environ['REQUESTS_CA_BUNDLE'] = ''\n",
    "    os.environ['CURL_CA_BUNDLE'] = ''\n",
    "    os.environ['DATABRICKS_INSECURE'] = '1'\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    VERIFY_SSL = False\n",
    "else:\n",
    "    VERIFY_SSL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "02237608",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dbc-935124bd-e5fd.cloud.databricks.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REST status: 200\n",
      "REST body (first 200): {}\n"
     ]
    }
   ],
   "source": [
    "# REST API diagnostic: can we reach the workspace?\n",
    "import requests, certifi, os\n",
    "host = os.getenv('DATABRICKS_HOST')\n",
    "token = os.getenv('DATABRICKS_TOKEN')\n",
    "rest_api_ok = None\n",
    "verify_arg = certifi.where() if globals().get('VERIFY_SSL', True) else False\n",
    "if not host or not token:\n",
    "    rest_api_ok = False\n",
    "    print('REST check skipped: missing DATABRICKS_HOST or DATABRICKS_TOKEN')\n",
    "else:\n",
    "    try:\n",
    "        r = requests.get(f\"{host}/api/2.0/clusters/list\", headers={\"Authorization\": f\"Bearer {token}\"}, timeout=10, verify=verify_arg)\n",
    "        print('REST status:', r.status_code)\n",
    "        print('REST body (first 200):', r.text[:200])\n",
    "        rest_api_ok = r.status_code == 200\n",
    "    except Exception as e:\n",
    "        rest_api_ok = False\n",
    "        print('REST connectivity error:', e)\n",
    "        print('Tip: Workspace REST permissions can be stricter than Spark connect. Spark attempts continue regardless of this result.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28938ce8",
   "metadata": {},
   "source": [
    "## Local dataset preview (runs even without Spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6a2c077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved CSV path: c:\\Users\\nnassili\\Documents\\life-style-mlops\\data\\raw\\Final_data.csv\n",
      "Local dataframe shape: (20000, 54)\n",
      "Local dataframe shape: (20000, 54)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>Height (m)</th>\n",
       "      <th>Max_BPM</th>\n",
       "      <th>Avg_BPM</th>\n",
       "      <th>Resting_BPM</th>\n",
       "      <th>Session_Duration (hours)</th>\n",
       "      <th>Calories_Burned</th>\n",
       "      <th>Workout_Type</th>\n",
       "      <th>...</th>\n",
       "      <th>cal_from_macros</th>\n",
       "      <th>pct_carbs</th>\n",
       "      <th>protein_per_kg</th>\n",
       "      <th>pct_HRR</th>\n",
       "      <th>pct_maxHR</th>\n",
       "      <th>cal_balance</th>\n",
       "      <th>lean_mass_kg</th>\n",
       "      <th>expected_burn</th>\n",
       "      <th>Burns Calories (per 30 min)_bc</th>\n",
       "      <th>Burns_Calories_Bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.91</td>\n",
       "      <td>Male</td>\n",
       "      <td>65.27</td>\n",
       "      <td>1.62</td>\n",
       "      <td>188.58</td>\n",
       "      <td>157.65</td>\n",
       "      <td>69.05</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1080.90</td>\n",
       "      <td>Strength</td>\n",
       "      <td>...</td>\n",
       "      <td>2139.59</td>\n",
       "      <td>0.500432</td>\n",
       "      <td>1.624789</td>\n",
       "      <td>0.741237</td>\n",
       "      <td>0.835985</td>\n",
       "      <td>725.10</td>\n",
       "      <td>47.777394</td>\n",
       "      <td>685.1600</td>\n",
       "      <td>7.260425e+19</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.37</td>\n",
       "      <td>Female</td>\n",
       "      <td>56.41</td>\n",
       "      <td>1.55</td>\n",
       "      <td>179.43</td>\n",
       "      <td>131.75</td>\n",
       "      <td>73.18</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1809.91</td>\n",
       "      <td>HIIT</td>\n",
       "      <td>...</td>\n",
       "      <td>1711.65</td>\n",
       "      <td>0.500850</td>\n",
       "      <td>1.514093</td>\n",
       "      <td>0.551247</td>\n",
       "      <td>0.734270</td>\n",
       "      <td>-232.91</td>\n",
       "      <td>40.809803</td>\n",
       "      <td>978.6184</td>\n",
       "      <td>1.020506e+20</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.20</td>\n",
       "      <td>Female</td>\n",
       "      <td>58.98</td>\n",
       "      <td>1.67</td>\n",
       "      <td>175.04</td>\n",
       "      <td>123.95</td>\n",
       "      <td>54.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>802.26</td>\n",
       "      <td>Cardio</td>\n",
       "      <td>...</td>\n",
       "      <td>1965.92</td>\n",
       "      <td>0.500610</td>\n",
       "      <td>1.663445</td>\n",
       "      <td>0.574534</td>\n",
       "      <td>0.708124</td>\n",
       "      <td>805.74</td>\n",
       "      <td>44.635580</td>\n",
       "      <td>654.5266</td>\n",
       "      <td>1.079607e+20</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.69</td>\n",
       "      <td>Female</td>\n",
       "      <td>93.78</td>\n",
       "      <td>1.70</td>\n",
       "      <td>191.21</td>\n",
       "      <td>155.10</td>\n",
       "      <td>50.07</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1450.79</td>\n",
       "      <td>HIIT</td>\n",
       "      <td>...</td>\n",
       "      <td>1627.28</td>\n",
       "      <td>0.499533</td>\n",
       "      <td>0.862017</td>\n",
       "      <td>0.744155</td>\n",
       "      <td>0.811150</td>\n",
       "      <td>1206.21</td>\n",
       "      <td>63.007432</td>\n",
       "      <td>773.6300</td>\n",
       "      <td>8.987921e+19</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.09</td>\n",
       "      <td>Male</td>\n",
       "      <td>52.42</td>\n",
       "      <td>1.88</td>\n",
       "      <td>193.58</td>\n",
       "      <td>152.88</td>\n",
       "      <td>70.84</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1166.40</td>\n",
       "      <td>Strength</td>\n",
       "      <td>...</td>\n",
       "      <td>2659.23</td>\n",
       "      <td>0.500581</td>\n",
       "      <td>2.538153</td>\n",
       "      <td>0.668405</td>\n",
       "      <td>0.789751</td>\n",
       "      <td>303.60</td>\n",
       "      <td>43.347504</td>\n",
       "      <td>711.4176</td>\n",
       "      <td>5.264685e+19</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Gender  Weight (kg)  Height (m)  Max_BPM  Avg_BPM  Resting_BPM  \\\n",
       "0  34.91    Male        65.27        1.62   188.58   157.65        69.05   \n",
       "1  23.37  Female        56.41        1.55   179.43   131.75        73.18   \n",
       "2  33.20  Female        58.98        1.67   175.04   123.95        54.96   \n",
       "3  38.69  Female        93.78        1.70   191.21   155.10        50.07   \n",
       "4  45.09    Male        52.42        1.88   193.58   152.88        70.84   \n",
       "\n",
       "   Session_Duration (hours)  Calories_Burned Workout_Type  ...  \\\n",
       "0                      1.00          1080.90     Strength  ...   \n",
       "1                      1.37          1809.91         HIIT  ...   \n",
       "2                      0.91           802.26       Cardio  ...   \n",
       "3                      1.10          1450.79         HIIT  ...   \n",
       "4                      1.08          1166.40     Strength  ...   \n",
       "\n",
       "   cal_from_macros  pct_carbs  protein_per_kg   pct_HRR  pct_maxHR  \\\n",
       "0          2139.59   0.500432        1.624789  0.741237   0.835985   \n",
       "1          1711.65   0.500850        1.514093  0.551247   0.734270   \n",
       "2          1965.92   0.500610        1.663445  0.574534   0.708124   \n",
       "3          1627.28   0.499533        0.862017  0.744155   0.811150   \n",
       "4          2659.23   0.500581        2.538153  0.668405   0.789751   \n",
       "\n",
       "   cal_balance  lean_mass_kg  expected_burn  Burns Calories (per 30 min)_bc  \\\n",
       "0       725.10     47.777394       685.1600                    7.260425e+19   \n",
       "1      -232.91     40.809803       978.6184                    1.020506e+20   \n",
       "2       805.74     44.635580       654.5266                    1.079607e+20   \n",
       "3      1206.21     63.007432       773.6300                    8.987921e+19   \n",
       "4       303.60     43.347504       711.4176                    5.264685e+19   \n",
       "\n",
       "   Burns_Calories_Bin  \n",
       "0              Medium  \n",
       "1                High  \n",
       "2                High  \n",
       "3                High  \n",
       "4                 Low  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd, os\n",
    "csv_rel_path = '../data/raw/Final_data.csv'\n",
    "csv_abs_path = os.path.abspath(os.path.join(os.getcwd(), csv_rel_path))\n",
    "print('Resolved CSV path:', csv_abs_path)\n",
    "try:\n",
    "    df_preview = pd.read_csv(csv_abs_path)\n",
    "    print('Local dataframe shape:', df_preview.shape)\n",
    "    display(df_preview.head())\n",
    "except Exception as e:\n",
    "    print('Local preview error:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d769e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using http_path from Databricks Connect config.\n",
      "Spark session created via Databricks Connect.\n",
      "Spark action error (likely connectivity/SSL): [RETRIES_EXCEEDED] The maximum number of retries has been exceeded.\n",
      "Hint: RETRIES_EXCEEDED usually means a proxy/SSL interceptor blocks gRPC. Consider importing corporate root certificates or toggling the debug override briefly.\n",
      "Spark action error (likely connectivity/SSL): [RETRIES_EXCEEDED] The maximum number of retries has been exceeded.\n",
      "Hint: RETRIES_EXCEEDED usually means a proxy/SSL interceptor blocks gRPC. Consider importing corporate root certificates or toggling the debug override briefly.\n"
     ]
    }
   ],
   "source": [
    "# Spark connectivity test with guard flag (always attempt session)\n",
    "spark_ok = False\n",
    "spark_session_error = None\n",
    "spark_action_error = None\n",
    "try:\n",
    "    from databricks.connect import DatabricksSession\n",
    "except Exception as import_error:\n",
    "    spark_session_error = import_error\n",
    "    print('databricks-connect import error:', import_error)\n",
    "else:\n",
    "    if globals().get('rest_api_ok') is False:\n",
    "        print('REST API check failed earlier; attempting Spark Connect anyway because REST permissions can be narrower than Spark.')\n",
    "    try:\n",
    "        session_builder = DatabricksSession.builder\n",
    "        if http_path:\n",
    "            print('Using http_path from Databricks Connect config.')\n",
    "        else:\n",
    "            remote_kwargs = {}\n",
    "            if host and token:\n",
    "                remote_kwargs['host'] = host\n",
    "                remote_kwargs['token'] = token\n",
    "            if cluster_id:\n",
    "                remote_kwargs['cluster_id'] = cluster_id\n",
    "            if remote_kwargs:\n",
    "                session_builder = session_builder.remote(**remote_kwargs)\n",
    "        spark = session_builder.getOrCreate()\n",
    "        print('Spark session created via Databricks Connect.')\n",
    "        spark_ok = True\n",
    "    except Exception as e:\n",
    "        spark_session_error = e\n",
    "        print('Spark session create error:', e)\n",
    "    if spark_ok:\n",
    "        try:\n",
    "            print('Spark SQL test:', spark.sql('SELECT CURRENT_CATALOG() AS catalog, CURRENT_SCHEMA() AS schema').collect())\n",
    "        except Exception as e:\n",
    "            spark_action_error = e\n",
    "            print('Spark action error (likely connectivity/SSL):', e)\n",
    "            print('Hint: RETRIES_EXCEEDED usually means a proxy/SSL interceptor blocks gRPC. Consider importing corporate root certificates or toggling the debug override briefly.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c3714b",
   "metadata": {},
   "source": [
    "## Catalog and schema bootstrap (Unity Catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03e60b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nnassili\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyspark\\sql\\connect\\client\\reattach.py:248: UserWarning: ReleaseExecute failed with exception: [RETRIES_EXCEEDED] The maximum number of retries has been exceeded..\n",
      "  warnings.warn(f\"ReleaseExecute failed with exception: {e}.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalog/schema step: [RETRIES_EXCEEDED] The maximum number of retries has been exceeded.\n",
      "Fallback target tables will use default.people\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "CATALOG_NAME = os.getenv('TARGET_CATALOG', 'lifestyle')\n",
    "SCHEMA_NAME = os.getenv('TARGET_SCHEMA', 'kaggle_ingest')\n",
    "TARGET_TABLE_NAME = os.getenv('TARGET_TABLE_NAME', 'people')\n",
    "SAMPLE_TABLE_NAME = os.getenv('SAMPLE_TABLE_NAME', f'{TARGET_TABLE_NAME}_sample')\n",
    "catalog_created = False\n",
    "schema_created = False\n",
    "try:\n",
    "    if not globals().get('spark_ok', False):\n",
    "        raise RuntimeError('Skipping catalog/schema creation: Spark not connected.')\n",
    "    spark.sql(f\"CREATE CATALOG IF NOT EXISTS `{CATALOG_NAME}`\")\n",
    "    catalog_created = True\n",
    "    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS `{CATALOG_NAME}`.`{SCHEMA_NAME}`\")\n",
    "    schema_created = True\n",
    "    spark.sql(f\"USE `{CATALOG_NAME}`.`{SCHEMA_NAME}`\")\n",
    "    TARGET_TABLE_FQN = f\"{CATALOG_NAME}.{SCHEMA_NAME}.{TARGET_TABLE_NAME}\"\n",
    "    SAMPLE_TABLE_FQN = f\"{CATALOG_NAME}.{SCHEMA_NAME}.{SAMPLE_TABLE_NAME}\"\n",
    "    print(f\"Catalog `{CATALOG_NAME}` and schema `{SCHEMA_NAME}` ready.\")\n",
    "except Exception as e:\n",
    "    TARGET_TABLE_FQN = f'default.{TARGET_TABLE_NAME}'\n",
    "    SAMPLE_TABLE_FQN = f'default.{SAMPLE_TABLE_NAME}'\n",
    "    print('Catalog/schema step:', e)\n",
    "    print(f'Fallback target tables will use {TARGET_TABLE_FQN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e109c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarded sample write to ensure connection works before big writes\n",
    "try:\n",
    "    if not globals().get('spark_ok', False):\n",
    "        raise RuntimeError('Skipping sample write: Spark not connected.')\n",
    "    sample_table = globals().get('SAMPLE_TABLE_FQN', 'default.people_sample')\n",
    "    import pandas as pd\n",
    "    sample_df = pd.DataFrame({'a': list(range(5))})\n",
    "    sdf_sample = spark.createDataFrame(sample_df)\n",
    "    sdf_sample.write.mode('overwrite').saveAsTable(sample_table)\n",
    "    print(f'OK: sample data written -> {sample_table}')\n",
    "except Exception as e:\n",
    "    print('Sample write step:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "682bf672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved CSV path: c:\\Users\\nnassili\\Documents\\life-style-mlops\\data\\raw\\Final_data.csv\n",
      "Loaded pandas DataFrame shape: (20000, 54)\n",
      "Full load/write step: [RETRIES_EXCEEDED] The maximum number of retries has been exceeded.\n",
      "Full load/write step: [RETRIES_EXCEEDED] The maximum number of retries has been exceeded.\n"
     ]
    }
   ],
   "source": [
    "# Load full CSV and (optionally) write to Delta table\n",
    "import pandas as pd, os\n",
    "DO_FULL_WRITE = True  # set to False to skip writing large data during troubleshooting\n",
    "if 'csv_abs_path' not in globals():\n",
    "    csv_rel_path = '../data/raw/Final_data.csv'\n",
    "    csv_abs_path = os.path.abspath(os.path.join(os.getcwd(), csv_rel_path))\n",
    "print('Resolved CSV path:', csv_abs_path)\n",
    "try:\n",
    "    df = df_preview if 'df_preview' in globals() else pd.read_csv(csv_abs_path)\n",
    "    print('Loaded pandas DataFrame shape:', df.shape)\n",
    "    if not globals().get('spark_ok', False):\n",
    "        raise RuntimeError('Skipping full write: Spark not connected.')\n",
    "    target_table = globals().get('TARGET_TABLE_FQN', 'default.people')\n",
    "    sdf = spark.createDataFrame(df)\n",
    "    print('Spark DataFrame count:', sdf.count())\n",
    "    if DO_FULL_WRITE:\n",
    "        sdf.write.mode('overwrite').saveAsTable(target_table)\n",
    "        print(f\"OK: data written -> {target_table}\")\n",
    "    else:\n",
    "        print('DO_FULL_WRITE is False; skipping write.')\n",
    "except Exception as e:\n",
    "    print('Full load/write step:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84819c29",
   "metadata": {},
   "source": [
    "## MLflow logging (optional once Spark connectivity works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0fcef135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (JitteredRetry(total=6, connect=7, read=7, redirect=7, status=7)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)'))': /api/2.0/mlflow/experiments/get-by-name?experiment_name=%2FShared%2Flifestyle-demo\n",
      "WARNING:urllib3.connectionpool:Retrying (JitteredRetry(total=5, connect=7, read=7, redirect=7, status=7)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)'))': /api/2.0/mlflow/experiments/get-by-name?experiment_name=%2FShared%2Flifestyle-demo\n",
      "WARNING:urllib3.connectionpool:Retrying (JitteredRetry(total=5, connect=7, read=7, redirect=7, status=7)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)'))': /api/2.0/mlflow/experiments/get-by-name?experiment_name=%2FShared%2Flifestyle-demo\n",
      "WARNING:urllib3.connectionpool:Retrying (JitteredRetry(total=4, connect=7, read=7, redirect=7, status=7)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)'))': /api/2.0/mlflow/experiments/get-by-name?experiment_name=%2FShared%2Flifestyle-demo\n",
      "WARNING:urllib3.connectionpool:Retrying (JitteredRetry(total=4, connect=7, read=7, redirect=7, status=7)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)'))': /api/2.0/mlflow/experiments/get-by-name?experiment_name=%2FShared%2Flifestyle-demo\n",
      "WARNING:urllib3.connectionpool:Retrying (JitteredRetry(total=3, connect=7, read=7, redirect=7, status=7)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)'))': /api/2.0/mlflow/experiments/get-by-name?experiment_name=%2FShared%2Flifestyle-demo\n",
      "WARNING:urllib3.connectionpool:Retrying (JitteredRetry(total=3, connect=7, read=7, redirect=7, status=7)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)'))': /api/2.0/mlflow/experiments/get-by-name?experiment_name=%2FShared%2Flifestyle-demo\n",
      "WARNING:urllib3.connectionpool:Retrying (JitteredRetry(total=2, connect=7, read=7, redirect=7, status=7)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)'))': /api/2.0/mlflow/experiments/get-by-name?experiment_name=%2FShared%2Flifestyle-demo\n",
      "WARNING:urllib3.connectionpool:Retrying (JitteredRetry(total=2, connect=7, read=7, redirect=7, status=7)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)'))': /api/2.0/mlflow/experiments/get-by-name?experiment_name=%2FShared%2Flifestyle-demo\n",
      "WARNING:urllib3.connectionpool:Retrying (JitteredRetry(total=1, connect=7, read=7, redirect=7, status=7)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)'))': /api/2.0/mlflow/experiments/get-by-name?experiment_name=%2FShared%2Flifestyle-demo\n",
      "WARNING:urllib3.connectionpool:Retrying (JitteredRetry(total=1, connect=7, read=7, redirect=7, status=7)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)'))': /api/2.0/mlflow/experiments/get-by-name?experiment_name=%2FShared%2Flifestyle-demo\n",
      "WARNING:urllib3.connectionpool:Retrying (JitteredRetry(total=0, connect=7, read=7, redirect=7, status=7)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)'))': /api/2.0/mlflow/experiments/get-by-name?experiment_name=%2FShared%2Flifestyle-demo\n",
      "WARNING:urllib3.connectionpool:Retrying (JitteredRetry(total=0, connect=7, read=7, redirect=7, status=7)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)'))': /api/2.0/mlflow/experiments/get-by-name?experiment_name=%2FShared%2Flifestyle-demo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow logging step: API request to https://dbc-935124bd-e5fd.cloud.databricks.com/api/2.0/mlflow/experiments/get-by-name failed with exception HTTPSConnectionPool(host='dbc-935124bd-e5fd.cloud.databricks.com', port=443): Max retries exceeded with url: /api/2.0/mlflow/experiments/get-by-name?experiment_name=%2FShared%2Flifestyle-demo (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n"
     ]
    }
   ],
   "source": [
    "import mlflow, os\n",
    "mlflow_ok = False\n",
    "try:\n",
    "    if not spark_ok:\n",
    "        raise RuntimeError('Skipping MLflow logging: Spark not connected.')\n",
    "    experiment_name = os.getenv('MLFLOW_EXPERIMENT_NAME', '/Shared/lifestyle-demo')\n",
    "    mlflow.set_tracking_uri(os.getenv('DATABRICKS_HOST'))\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    with mlflow.start_run(run_name='connect_sanity_check'):\n",
    "        mlflow.log_param('rows_loaded', int(df_preview.shape[0]) if 'df_preview' in globals() else None)\n",
    "        mlflow.log_param('table_target', globals().get('TARGET_TABLE_FQN', 'default.people'))\n",
    "        mlflow.log_metric('spark_connect_success', 1 if spark_ok else 0)\n",
    "        mlflow_ok = True\n",
    "    print(f\"MLflow run logged to experiment: {experiment_name}\")\n",
    "except Exception as e:\n",
    "    print('MLflow logging step:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea024549",
   "metadata": {},
   "source": [
    "## Run summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6106ca16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'databricks_connect_ok': True, 'rest_api_ok': False, 'spark_session_error': None, 'spark_action_error': '[RETRIES_EXCEEDED] The maximum number of retries has been exceeded.', 'spark_ok': True, 'catalog_created': False, 'schema_created': False, 'target_table': 'default.people', 'sample_write_attempted': False, 'full_write_attempted': True, 'mlflow_ok': False}\n",
      "REST API note: token/host responded with an error, but Databricks Connect can still work if Spark succeeded. Double-check permissions if REST access is needed.\n"
     ]
    }
   ],
   "source": [
    "summary = {\n",
    "    'databricks_connect_ok': databricks_connect_ok if 'databricks_connect_ok' in globals() else False,\n",
    "    'rest_api_ok': rest_api_ok if 'rest_api_ok' in globals() else None,\n",
    "    'spark_session_error': str(spark_session_error) if 'spark_session_error' in globals() and spark_session_error else None,\n",
    "    'spark_action_error': str(spark_action_error) if 'spark_action_error' in globals() and spark_action_error else None,\n",
    "    'spark_ok': spark_ok if 'spark_ok' in globals() else False,\n",
    "    'combined_ca_bundle': str(combined_ca_bundle) if 'combined_ca_bundle' in globals() and combined_ca_bundle else None,\n",
    "    'catalog_created': globals().get('catalog_created', False),\n",
    "    'schema_created': globals().get('schema_created', False),\n",
    "    'target_table': globals().get('TARGET_TABLE_FQN'),\n",
    "    'sample_write_attempted': bool('sdf_sample' in globals()),\n",
    "    'full_write_attempted': bool('DO_FULL_WRITE' in globals() and DO_FULL_WRITE),\n",
    "    'mlflow_ok': mlflow_ok if 'mlflow_ok' in globals() else False\n",
    "}\n",
    "print(summary)\n",
    "if not summary['databricks_connect_ok']:\n",
    "    print('Install/configure databricks-connect: `pip install databricks-connect` then `databricks-connect configure`.')\n",
    "if summary['combined_ca_bundle'] is None:\n",
    "    print('No corporate CA merged. If Spark Connect retries persist, export your proxy root certificate to PEM and set CORPORATE_CA_BUNDLE.')\n",
    "if not summary['spark_ok'] or summary['spark_action_error']:\n",
    "    print('Next steps:')\n",
    "    if summary['spark_session_error']:\n",
    "        print(' - Spark session could not be created. Confirm compute (SQL warehouse or cluster) is running and config matches.')\n",
    "    if summary['spark_action_error'] and 'RETRIES_EXCEEDED' in summary['spark_action_error']:\n",
    "        print(' - Spark action hit RETRIES_EXCEEDED. Merge your corporate CA (per Spark Connect TLS docs) or toggle DISABLE_SSL_VERIFY briefly for proof.')\n",
    "if summary['rest_api_ok'] is False:\n",
    "    print('REST API note: token/host responded with an error, but Databricks Connect can still work if Spark succeeded. Double-check permissions if REST access is needed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b71bac9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verify step: [RETRIES_EXCEEDED] The maximum number of retries has been exceeded.\n"
     ]
    }
   ],
   "source": [
    "# Verify schema and preview data (guarded)\n",
    "try:\n",
    "    if not globals().get('spark_ok', False):\n",
    "        raise RuntimeError('Skipping verification: Spark not connected.')\n",
    "    target_table = globals().get('TARGET_TABLE_FQN', 'default.people')\n",
    "    spark.sql(f\"DESCRIBE TABLE {target_table}\").show(truncate=False)\n",
    "    spark.sql(f\"SELECT * FROM {target_table} LIMIT 5\").show(truncate=False)\n",
    "except Exception as e:\n",
    "    print('Verify step:', e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
